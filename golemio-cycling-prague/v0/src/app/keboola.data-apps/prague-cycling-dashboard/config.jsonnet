{
  storage: [],
  parameters: {
    size: "tiny",
    dataApp: {
      slug: "prague-cycling",
      streamlit: {
        code: "import streamlit as st\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport warnings\nfrom keboola_streamlit import KeboolaStreamlit\nimport os\n\nwarnings.filterwarnings('ignore')\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Prague Cycling Dashboard\",\n    page_icon=\"üö¥\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Custom CSS for better styling\nst.markdown(\"\"\"\n\u003cstyle\u003e\n    .main-header {\n        font-size: 3rem;\n        font-weight: bold;\n        color: #1f77b4;\n        text-align: center;\n        margin-bottom: 2rem;\n    }\n    .metric-card {\n        background-color: #f0f2f6;\n        padding: 1rem;\n        border-radius: 0.5rem;\n        margin: 0.5rem 0;\n    }\n    .sidebar-content {\n        background-color: #f8f9fa;\n        padding: 1rem;\n        border-radius: 0.5rem;\n        margin-bottom: 1rem;\n    }\n\u003c/style\u003e\n\"\"\", unsafe_allow_html=True)\n\n# Initialize Keboola client\n@st.cache_resource\ndef init_keboola():\n    try:\n        TOKEN = os.environ.get('KBC_TOKEN')\n        URL = os.environ.get('KBC_URL')\n        if TOKEN and URL:\n            return KeboolaStreamlit(root_url=URL, token=TOKEN)\n        else:\n            st.error(\"Keboola credentials not found in environment variables\")\n            return None\n    except Exception as e:\n        st.error(f\"Error initializing Keboola client: {e}\")\n        return None\n\n# Load data function\n@st.cache_data\ndef load_data():\n    \"\"\"\n    Load data from Keboola tables using keboola-streamlit package\n    \"\"\"\n    keboola = init_keboola()\n    \n    if keboola:\n        try:\n            # Try to load from the analytical table first\n            try:\n                df = keboola.read_table(\"out.c-Cycling-Analytics-Weekly-Summary.cyclists_weekly_summary\")\n                \n                # Convert column names to lowercase for consistency\n                df.columns = [col.lower() for col in df.columns]\n                \n                # Convert dates\n                df['measured_from'] = pd.to_datetime(df['measured_from'])\n                df['measured_to'] = pd.to_datetime(df['measured_to'])\n                df['week_start'] = pd.to_datetime(df['week_start'])\n                \n                return df\n                \n            except Exception as e:\n                st.warning(f\"Could not load analytical table: {e}\")\n                # Fallback to loading and joining original tables\n                st.info(\"Loading from original tables...\")\n                \n                # Load individual tables\n                counters_df = keboola.read_table(\"in.c-cycling_in_prague.bicycle_counters\")\n                directions_df = keboola.read_table(\"in.c-cycling_in_prague.bicycle_counters_directions\")\n                observations_df = keboola.read_table(\"out.c-cyclists-in-prague.bicycles_observations\")\n                \n                # Merge the data\n                merged_df = observations_df.merge(\n                    counters_df, \n                    left_on='location_id', \n                    right_on='id', \n                    how='left'\n                ).merge(\n                    directions_df,\n                    left_on='location_direction_id',\n                    right_on='direction_id',\n                    how='left'\n                )\n                \n                # Create additional columns\n                merged_df['location_name'] = merged_df['name']\n                merged_df['latitude'] = merged_df['lat']\n                merged_df['longitude'] = merged_df['lon']\n                merged_df['direction'] = merged_df['direction_name']\n                \n                # Convert dates\n                merged_df['measured_from'] = pd.to_datetime(merged_df['measured_from'])\n                merged_df['measured_to'] = pd.to_datetime(merged_df['measured_to'])\n                merged_df['week_start'] = merged_df['measured_from'].dt.to_period('W').dt.start_time\n                merged_df['week_label'] = merged_df['measured_from'].dt.strftime('%Y-W%U')\n                \n                return merged_df\n                \n        except Exception as e:\n            st.error(f\"Error loading data from Keboola: {e}\")\n            return create_sample_data()\n    else:\n        st.warning(\"Keboola client not available, using sample data\")\n        return create_sample_data()\n\ndef create_sample_data():\n    \"\"\"\n    Create sample data for demonstration when Keboola is not available\n    \"\"\"\n    locations_data = {\n        'id': ['camea-BC_CL-PVLI', 'camea-BC_CT-OTPB', 'camea-BC_DS-KJVL', 'camea-BC_EU-KTOT'],\n        'name': ['U ƒåesk√Ωch lodƒõnic', 'Celetn√°', 'Dukelsk√Ωch hrdin≈Ø', 'Elsnicovo n√°mƒõst√≠'],\n        'route': ['A2', 'A 1', 'A 310', 'A 2'],\n        'lat': [50.1135103, 50.087262, 50.0973149, 50.106999],\n        'lon': [14.4581003, 14.425974, 14.432982, 14.470749]\n    }\n    \n    directions_data = {\n        'direction_id': ['camea-BC_CL-LI', 'camea-BC_CT-OT', 'camea-BC_DS-KJ', 'camea-BC_EU-KT'],\n        'direction_name': ['Libe≈à', 'Obecn√≠ d≈Øm', 'Karl√≠n', 'k Thomayerov√Ωm sad≈Øm'],\n        'counter_id': ['camea-BC_CL-PVLI', 'camea-BC_CT-OTPB', 'camea-BC_DS-KJVL', 'camea-BC_EU-KTOT']\n    }\n    \n    # Generate sample observations data\n    observations_data = []\n    locations = locations_data['id']\n    directions = directions_data['direction_id']\n    \n    # Generate weekly data for the last 3 weeks\n    start_date = datetime(2025, 6, 23)\n    for week in range(3):\n        week_start = start_date + timedelta(weeks=week)\n        week_end = week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)\n        \n        for i, location in enumerate(locations):\n            cyclists_count = np.random.randint(300, 4000)\n            observations_data.append({\n                'location_id': location,\n                'location_name': locations_data['name'][i],\n                'route': locations_data['route'][i],\n                'latitude': locations_data['lat'][i],\n                'longitude': locations_data['lon'][i],\n                'direction': directions_data['direction_name'][i],\n                'location_direction_id': directions[i],\n                'observed_cyclists': cyclists_count,\n                'measured_from': week_start,\n                'measured_to': week_end,\n                'week_start': week_start,\n                'week_label': f\"{week_start.year}-W{week_start.isocalendar()[1]:02d}\"\n            })\n    \n    return pd.DataFrame(observations_data)\n\n# Get processed data\n@st.cache_data\ndef get_processed_data():\n    df = load_data()\n    \n    # Ensure date columns are datetime\n    date_cols = ['measured_from', 'measured_to', 'week_start']\n    for col in date_cols:\n        if col in df.columns:\n            df[col] = pd.to_datetime(df[col])\n    \n    return df\n\n# Main app\ndef main():\n    # Header\n    st.markdown('\u003ch1 class=\"main-header\"\u003eüö¥ Prague Cycling Dashboard\u003c/h1\u003e', unsafe_allow_html=True)\n    \n    # Load data\n    df = get_processed_data()\n    \n    # Sidebar filters\n    st.sidebar.markdown(\"## üîç Filters\")\n    \n    # Location filter\n    locations = ['All'] + sorted(df['location_name'].unique().tolist())\n    selected_locations = st.sidebar.multiselect(\n        \"Select Locations\",\n        options=locations,\n        default=['All']\n    )\n    \n    # Direction filter\n    directions = ['All'] + sorted(df['direction'].unique().tolist())\n    selected_directions = st.sidebar.multiselect(\n        \"Select Directions\",\n        options=directions,\n        default=['All']\n    )\n    \n    # Date range filter\n    min_date = df['week_start'].min().date()\n    max_date = df['week_start'].max().date()\n    \n    date_range = st.sidebar.date_input(\n        \"Select Date Range\",\n        value=(min_date, max_date),\n        min_value=min_date,\n        max_value=max_date\n    )\n    \n    # Filter data\n    filtered_df = df.copy()\n    \n    # Apply location filter\n    if 'All' not in selected_locations:\n        filtered_df = filtered_df[filtered_df['location_name'].isin(selected_locations)]\n    \n    # Apply direction filter\n    if 'All' not in selected_directions:\n        filtered_df = filtered_df[filtered_df['direction'].isin(selected_directions)]\n    \n    # Apply date filter\n    if len(date_range) == 2:\n        start_date, end_date = date_range\n        filtered_df = filtered_df[\n            (filtered_df['week_start'].dt.date \u003e= start_date) \u0026\n            (filtered_df['week_start'].dt.date \u003c= end_date)\n        ]\n    \n    # Main content\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        total_cyclists = filtered_df['observed_cyclists'].sum()\n        st.metric(\"Total Cyclists\", f\"{total_cyclists:,}\")\n    \n    with col2:\n        avg_cyclists = filtered_df['observed_cyclists'].mean()\n        st.metric(\"Average per Week\", f\"{avg_cyclists:,.0f}\")\n    \n    with col3:\n        unique_locations = filtered_df['location_name'].nunique()\n        st.metric(\"Active Locations\", unique_locations)\n    \n    with col4:\n        unique_directions = filtered_df['direction'].nunique()\n        st.metric(\"Monitored Directions\", unique_directions)\n    \n    # Charts\n    st.markdown(\"---\")\n    \n    # Time series chart\n    st.subheader(\"üìà Cycling Trends Over Time\")\n    \n    # Aggregate by week\n    weekly_data = filtered_df.groupby(['week_label', 'week_start'])['observed_cyclists'].sum().reset_index()\n    weekly_data = weekly_data.sort_values('week_start')\n    \n    fig_time = px.line(\n        weekly_data,\n        x='week_label',\n        y='observed_cyclists',\n        title=\"Total Cyclists by Week\",\n        labels={'observed_cyclists': 'Number of Cyclists', 'week_label': 'Week'},\n        line_shape='linear'\n    )\n    fig_time.update_layout(height=400)\n    st.plotly_chart(fig_time, use_container_width=True)\n    \n    # Location comparison\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"üìç Cyclists by Location\")\n        location_data = filtered_df.groupby('location_name')['observed_cyclists'].sum().reset_index()\n        location_data = location_data.sort_values('observed_cyclists', ascending=True)\n        \n        fig_location = px.bar(\n            location_data,\n            x='observed_cyclists',\n            y='location_name',\n            orientation='h',\n            title=\"Total Cyclists by Location\",\n            labels={'observed_cyclists': 'Number of Cyclists', 'location_name': 'Location'}\n        )\n        fig_location.update_layout(height=400)\n        st.plotly_chart(fig_location, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"üß≠ Cyclists by Direction\")\n        direction_data = filtered_df.groupby('direction')['observed_cyclists'].sum().reset_index()\n        direction_data = direction_data.sort_values('observed_cyclists', ascending=False)\n        \n        fig_direction = px.pie(\n            direction_data,\n            values='observed_cyclists',\n            names='direction',\n            title=\"Distribution by Direction\"\n        )\n        fig_direction.update_layout(height=400)\n        st.plotly_chart(fig_direction, use_container_width=True)\n    \n    # Heatmap\n    st.subheader(\"üî• Weekly Activity Heatmap\")\n    \n    # Create heatmap data\n    heatmap_data = filtered_df.pivot_table(\n        index='location_name',\n        columns='week_label',\n        values='observed_cyclists',\n        aggfunc='sum',\n        fill_value=0\n    )\n    \n    fig_heatmap = px.imshow(\n        heatmap_data,\n        title=\"Cycling Activity Heatmap (Locations vs Weeks)\",\n        labels=dict(x=\"Week\", y=\"Location\", color=\"Cyclists\"),\n        aspect=\"auto\"\n    )\n    fig_heatmap.update_layout(height=400)\n    st.plotly_chart(fig_heatmap, use_container_width=True)\n    \n    # Map view\n    st.subheader(\"üó∫Ô∏è Cycling Locations Map\")\n    \n    # Aggregate data for map\n    map_data = filtered_df.groupby(['location_name', 'latitude', 'longitude']).agg({\n        'observed_cyclists': 'sum',\n        'route': 'first'\n    }).reset_index()\n    \n    # Create map\n    fig_map = px.scatter_mapbox(\n        map_data,\n        lat='latitude',\n        lon='longitude',\n        size='observed_cyclists',\n        color='observed_cyclists',\n        hover_name='location_name',\n        hover_data={'route': True, 'observed_cyclists': True},\n        title=\"Cycling Counter Locations\",\n        mapbox_style=\"open-street-map\",\n        zoom=11,\n        height=500\n    )\n    st.plotly_chart(fig_map, use_container_width=True)\n    \n    # Data table\n    st.subheader(\"üìä Detailed Data\")\n    \n    # Display filtered data\n    display_df = filtered_df[['location_name', 'direction', 'week_label', 'observed_cyclists', 'route']].copy()\n    display_df = display_df.sort_values(['week_label', 'location_name'])\n    \n    st.dataframe(\n        display_df,\n        use_container_width=True,\n        hide_index=True\n    )\n    \n    # Additional features\n    st.markdown(\"---\")\n    \n    # Summary statistics\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"üìä Summary Statistics\")\n        \n        # Peak activity location\n        peak_location = filtered_df.groupby('location_name')['observed_cyclists'].sum().idxmax()\n        peak_count = filtered_df.groupby('location_name')['observed_cyclists'].sum().max()\n        \n        # Best performing week\n        best_week = filtered_df.groupby('week_label')['observed_cyclists'].sum().idxmax()\n        best_week_count = filtered_df.groupby('week_label')['observed_cyclists'].sum().max()\n        \n        st.write(f\"**Peak Activity Location:** {peak_location} ({peak_count:,} cyclists)\")\n        st.write(f\"**Best Week:** {best_week} ({best_week_count:,} cyclists)\")\n        \n        # Average by direction\n        avg_by_direction = filtered_df.groupby('direction')['observed_cyclists'].mean().round(0)\n        st.write(\"**Average by Direction:**\")\n        for direction, avg in avg_by_direction.items():\n            st.write(f\"  ‚Ä¢ {direction}: {avg:,.0f} cyclists\")\n    \n    with col2:\n        st.subheader(\"üîÑ Data Refresh\")\n        \n        # Add refresh button\n        if st.button(\"üîÑ Refresh Data\"):\n            st.cache_data.clear()\n            st.rerun()\n        \n        # Data info\n        st.write(f\"**Data Range:** {filtered_df['measured_from'].min().strftime('%Y-%m-%d')} to {filtered_df['measured_to'].max().strftime('%Y-%m-%d')}\")\n        st.write(f\"**Total Records:** {len(filtered_df):,}\")\n        st.write(f\"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        \n        # Data quality info\n        missing_data = filtered_df['observed_cyclists'].isna().sum()\n        if missing_data \u003e 0:\n            st.warning(f\"‚ö†Ô∏è {missing_data} records with missing data\")\n        else:\n            st.success(\"‚úÖ No missing data detected\")\n    \n    # Footer\n    st.markdown(\"---\")\n    st.markdown(\n        \"\"\"\n        \u003cdiv style='text-align: center; color: #666; margin-top: 2rem;'\u003e\n            \u003cp\u003eüö¥ Prague Cycling Dashboard | Data from Keboola | Built with Streamlit\u003c/p\u003e\n            \u003cp\u003e\u003csmall\u003eKeboola Project: DEV - Jan Botorek | Real-time cycling analytics\u003c/small\u003e\u003c/p\u003e\n        \u003c/div\u003e\n        \"\"\",\n        unsafe_allow_html=True\n    )\n\nif __name__ == \"__main__\":\n    main()\n",
        packages: [
          "keboola-streamlit",
          "plotly",
          "pandas",
          "numpy",
        ],
        "config.toml": '[theme]\nfont = "sans serif"\ntextColor = "#222529"\nbackgroundColor = "#FFFFFF"\nsecondaryBackgroundColor = "#E6F2FF"\nprimaryColor = "#1F8FFF"',
      },
    },
    autoSuspendAfterSeconds: 900,
    packages: [
      "keboola-streamlit",
      "plotly",
      "pandas",
      "numpy",
    ],
    script: [
      "import streamlit as st\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport warnings\nfrom keboola_streamlit import KeboolaStreamlit\nimport os\n\nwarnings.filterwarnings('ignore')\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Prague Cycling Dashboard\",\n    page_icon=\"üö¥\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Custom CSS for better styling\nst.markdown(\"\"\"\n\u003cstyle\u003e\n    .main-header {\n        font-size: 3rem;\n        font-weight: bold;\n        color: #1f77b4;\n        text-align: center;\n        margin-bottom: 2rem;\n    }\n    .metric-card {\n        background-color: #f0f2f6;\n        padding: 1rem;\n        border-radius: 0.5rem;\n        margin: 0.5rem 0;\n    }\n    .sidebar-content {\n        background-color: #f8f9fa;\n        padding: 1rem;\n        border-radius: 0.5rem;\n        margin-bottom: 1rem;\n    }\n    .stAlert {\n        margin-top: 1rem;\n    }\n\u003c/style\u003e\n\"\"\", unsafe_allow_html=True)\n\n# Initialize Keboola client\n@st.cache_resource\ndef init_keboola():\n    \"\"\"Initialize Keboola client with environment variables\"\"\"\n    try:\n        TOKEN = os.environ.get('KBC_TOKEN')\n        URL = os.environ.get('KBC_URL')\n        if TOKEN and URL:\n            return KeboolaStreamlit(root_url=URL, token=TOKEN)\n        else:\n            st.error(\"üîë Keboola credentials not found in environment variables\")\n            return None\n    except Exception as e:\n        st.error(f\"‚ùå Error initializing Keboola client: {e}\")\n        return None\n\n# Load data function\n@st.cache_data\ndef load_data():\n    \"\"\"Load data from Keboola tables using keboola-streamlit package\"\"\"\n    keboola = init_keboola()\n    \n    if keboola:\n        try:\n            # Try to load from the analytical table first\n            try:\n                st.info(\"üìä Loading analytical data...\")\n                df = keboola.read_table(\"out.c-Cycling-Analytics-Weekly-Summary.cyclists_weekly_summary\")\n                \n                # Convert column names to lowercase for consistency\n                df.columns = [col.lower() for col in df.columns]\n                \n                # Convert dates and handle different formats\n                date_cols = ['measured_from', 'measured_to', 'week_start']\n                for col in date_cols:\n                    if col in df.columns:\n                        df[col] = pd.to_datetime(df[col])\n                \n                st.success(\"‚úÖ Successfully loaded analytical data!\")\n                return df\n                \n            except Exception as e:\n                st.warning(f\"‚ö†Ô∏è Could not load analytical table: {e}\")\n                # Fallback to loading and joining original tables\n                st.info(\"üîÑ Loading from original tables...\")\n                \n                # Load individual tables\n                counters_df = keboola.read_table(\"in.c-cycling_in_prague.bicycle_counters\")\n                directions_df = keboola.read_table(\"in.c-cycling_in_prague.bicycle_counters_directions\")\n                observations_df = keboola.read_table(\"out.c-cyclists-in-prague.bicycles_observations\")\n                \n                # Merge the data\n                merged_df = observations_df.merge(\n                    counters_df, \n                    left_on='location_id', \n                    right_on='id', \n                    how='left'\n                ).merge(\n                    directions_df,\n                    left_on='location_direction_id',\n                    right_on='direction_id',\n                    how='left'\n                )\n                \n                # Create additional columns\n                merged_df['location_name'] = merged_df['name']\n                merged_df['latitude'] = merged_df['lat']\n                merged_df['longitude'] = merged_df['lon']\n                merged_df['direction'] = merged_df['direction_name']\n                \n                # Convert dates\n                merged_df['measured_from'] = pd.to_datetime(merged_df['measured_from'])\n                merged_df['measured_to'] = pd.to_datetime(merged_df['measured_to'])\n                merged_df['week_start'] = merged_df['measured_from'].dt.to_period('W').dt.start_time\n                merged_df['week_label'] = merged_df['measured_from'].dt.strftime('%Y-W%U')\n                \n                st.success(\"‚úÖ Successfully loaded and merged original tables!\")\n                return merged_df\n                \n        except Exception as e:\n            st.error(f\"‚ùå Error loading data from Keboola: {e}\")\n            st.info(\"üîÑ Falling back to sample data...\")\n            return create_sample_data()\n    else:\n        st.warning(\"‚ö†Ô∏è Keboola client not available, using sample data\")\n        return create_sample_data()\n\ndef create_sample_data():\n    \"\"\"Create sample data for demonstration when Keboola is not available\"\"\"\n    st.info(\"üìã Creating sample data for demonstration...\")\n    \n    locations_data = {\n        'id': ['camea-BC_CL-PVLI', 'camea-BC_CT-OTPB', 'camea-BC_DS-KJVL', 'camea-BC_EU-KTOT', 'camea-BC_HY-WINP'],\n        'name': ['U ƒåesk√Ωch lodƒõnic', 'Celetn√°', 'Dukelsk√Ωch hrdin≈Ø', 'Elsnicovo n√°mƒõst√≠', 'Hybernsk√°'],\n        'route': ['A2', 'A 1', 'A 310', 'A 2', 'A25'],\n        'lat': [50.1135103, 50.087262, 50.0973149, 50.106999, 50.0872642],\n        'lon': [14.4581003, 14.425974, 14.432982, 14.470749, 14.4344272]\n    }\n    \n    directions_data = {\n        'direction_id': ['camea-BC_CL-LI', 'camea-BC_CT-OT', 'camea-BC_DS-KJ', 'camea-BC_EU-KT', 'camea-BC_HY-WI'],\n        'direction_name': ['Libe≈à', 'Obecn√≠ d≈Øm', 'Karl√≠n', 'k Thomayerov√Ωm sad≈Øm', 'Wilsonova'],\n        'counter_id': ['camea-BC_CL-PVLI', 'camea-BC_CT-OTPB', 'camea-BC_DS-KJVL', 'camea-BC_EU-KTOT', 'camea-BC_HY-WINP']\n    }\n    \n    # Generate sample observations data\n    observations_data = []\n    locations = locations_data['id']\n    directions = directions_data['direction_id']\n    \n    # Generate weekly data for the last 4 weeks\n    start_date = datetime(2025, 6, 16)\n    for week in range(4):\n        week_start = start_date + timedelta(weeks=week)\n        week_end = week_start + timedelta(days=6, hours=23, minutes=59, seconds=59)\n        \n        for i, location in enumerate(locations):\n            # Generate realistic cycling data with some variation\n            base_count = np.random.randint(800, 3500)\n            # Add some weekly variation\n            weekly_variation = np.random.uniform(0.8, 1.2)\n            cyclists_count = int(base_count * weekly_variation)\n            \n            observations_data.append({\n                'location_id': location,\n                'location_name': locations_data['name'][i],\n                'route': locations_data['route'][i],\n                'latitude': locations_data['lat'][i],\n                'longitude': locations_data['lon'][i],\n                'direction': directions_data['direction_name'][i],\n                'location_direction_id': directions[i],\n                'observed_cyclists': cyclists_count,\n                'measured_from': week_start,\n                'measured_to': week_end,\n                'week_start': week_start,\n                'week_label': f\"{week_start.year}-W{week_start.isocalendar()[1]:02d}\"\n            })\n    \n    return pd.DataFrame(observations_data)\n\n# Get processed data\n@st.cache_data\ndef get_processed_data():\n    \"\"\"Get and process the data for the dashboard\"\"\"\n    df = load_data()\n    \n    # Ensure date columns are datetime\n    date_cols = ['measured_from', 'measured_to', 'week_start']\n    for col in date_cols:\n        if col in df.columns:\n            df[col] = pd.to_datetime(df[col])\n    \n    # Create week labels if not present\n    if 'week_label' not in df.columns:\n        df['week_label'] = df['week_start'].dt.strftime('%Y-W%U')\n    \n    return df\n\n# Main app\ndef main():\n    # Header\n    st.markdown('\u003ch1 class=\"main-header\"\u003eüö¥ Prague Cycling Dashboard\u003c/h1\u003e', unsafe_allow_html=True)\n    \n    # Load data\n    with st.spinner(\"Loading data...\"):\n        df = get_processed_data()\n    \n    # Check if data is available\n    if df.empty:\n        st.error(\"‚ùå No data available. Please check your data sources.\")\n        return\n    \n    # Sidebar filters\n    with st.sidebar:\n        st.markdown(\"## üîç Filters\")\n        \n        # Location filter\n        locations = ['All'] + sorted(df['location_name'].unique().tolist())\n        selected_locations = st.multiselect(\n            \"Select Locations\",\n            options=locations,\n            default=['All'],\n            help=\"Choose specific locations to analyze\"\n        )\n        \n        # Direction filter\n        directions = ['All'] + sorted(df['direction'].unique().tolist())\n        selected_directions = st.multiselect(\n            \"Select Directions\",\n            options=directions,\n            default=['All'],\n            help=\"Filter by traffic direction\"\n        )\n        \n        # Date range filter\n        min_date = df['week_start'].min().date()\n        max_date = df['week_start'].max().date()\n        \n        date_range = st.date_input(\n            \"Select Date Range\",\n            value=(min_date, max_date),\n            min_value=min_date,\n            max_value=max_date,\n            help=\"Choose time period for analysis\"\n        )\n        \n        # Data refresh button\n        if st.button(\"üîÑ Refresh Data\", help=\"Reload data from Keboola\"):\n            st.cache_data.clear()\n            st.rerun()\n    \n    # Filter data based on selections\n    filtered_df = df.copy()\n    \n    # Apply location filter\n    if 'All' not in selected_locations:\n        filtered_df = filtered_df[filtered_df['location_name'].isin(selected_locations)]\n    \n    # Apply direction filter\n    if 'All' not in selected_directions:\n        filtered_df = filtered_df[filtered_df['direction'].isin(selected_directions)]\n    \n    # Apply date filter\n    if len(date_range) == 2:\n        start_date, end_date = date_range\n        filtered_df = filtered_df[\n            (filtered_df['week_start'].dt.date \u003e= start_date) \u0026\n            (filtered_df['week_start'].dt.date \u003c= end_date)\n        ]\n    \n    # Check if filtered data is empty\n    if filtered_df.empty:\n        st.warning(\"‚ö†Ô∏è No data matches your current filters. Please adjust your selections.\")\n        return\n    \n    # Main metrics\n    col1, col2, col3, col4 = st.columns(4)\n    \n    with col1:\n        total_cyclists = filtered_df['observed_cyclists'].sum()\n        st.metric(\"Total Cyclists\", f\"{total_cyclists:,}\")\n    \n    with col2:\n        avg_cyclists = filtered_df['observed_cyclists'].mean()\n        st.metric(\"Average per Week\", f\"{avg_cyclists:,.0f}\")\n    \n    with col3:\n        unique_locations = filtered_df['location_name'].nunique()\n        st.metric(\"Active Locations\", unique_locations)\n    \n    with col4:\n        unique_directions = filtered_df['direction'].nunique()\n        st.metric(\"Monitored Directions\", unique_directions)\n    \n    # Charts section\n    st.markdown(\"---\")\n    \n    # Time series chart\n    st.subheader(\"üìà Cycling Trends Over Time\")\n    \n    # Aggregate by week\n    weekly_data = filtered_df.groupby(['week_label', 'week_start'])['observed_cyclists'].sum().reset_index()\n    weekly_data = weekly_data.sort_values('week_start')\n    \n    if not weekly_data.empty:\n        fig_time = px.line(\n            weekly_data,\n            x='week_label',\n            y='observed_cyclists',\n            title=\"Total Cyclists by Week\",\n            labels={'observed_cyclists': 'Number of Cyclists', 'week_label': 'Week'},\n            line_shape='linear'\n        )\n        fig_time.update_layout(height=400)\n        st.plotly_chart(fig_time, use_container_width=True)\n    \n    # Two-column layout for charts\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"üìç Cyclists by Location\")\n        location_data = filtered_df.groupby('location_name')['observed_cyclists'].sum().reset_index()\n        location_data = location_data.sort_values('observed_cyclists', ascending=True)\n        \n        if not location_data.empty:\n            fig_location = px.bar(\n                location_data,\n                x='observed_cyclists',\n                y='location_name',\n                orientation='h',\n                title=\"Total Cyclists by Location\",\n                labels={'observed_cyclists': 'Number of Cyclists', 'location_name': 'Location'}\n            )\n            fig_location.update_layout(height=400)\n            st.plotly_chart(fig_location, use_container_width=True)\n    \n    with col2:\n        st.subheader(\"üß≠ Cyclists by Direction\")\n        direction_data = filtered_df.groupby('direction')['observed_cyclists'].sum().reset_index()\n        direction_data = direction_data.sort_values('observed_cyclists', ascending=False)\n        \n        if not direction_data.empty:\n            fig_direction = px.pie(\n                direction_data,\n                values='observed_cyclists',\n                names='direction',\n                title=\"Distribution by Direction\"\n            )\n            fig_direction.update_layout(height=400)\n            st.plotly_chart(fig_direction, use_container_width=True)\n    \n    # Heatmap\n    st.subheader(\"üî• Weekly Activity Heatmap\")\n    \n    # Create heatmap data\n    heatmap_data = filtered_df.pivot_table(\n        index='location_name',\n        columns='week_label',\n        values='observed_cyclists',\n        aggfunc='sum',\n        fill_value=0\n    )\n    \n    if not heatmap_data.empty:\n        fig_heatmap = px.imshow(\n            heatmap_data,\n            title=\"Cycling Activity Heatmap (Locations vs Weeks)\",\n            labels=dict(x=\"Week\", y=\"Location\", color=\"Cyclists\"),\n            aspect=\"auto\"\n        )\n        fig_heatmap.update_layout(height=400)\n        st.plotly_chart(fig_heatmap, use_container_width=True)\n    \n    # Map view\n    st.subheader(\"üó∫Ô∏è Cycling Locations Map\")\n    \n    # Aggregate data for map\n    map_data = filtered_df.groupby(['location_name', 'latitude', 'longitude']).agg({\n        'observed_cyclists': 'sum',\n        'route': 'first'\n    }).reset_index()\n    \n    if not map_data.empty:\n        # Create map\n        fig_map = px.scatter_mapbox(\n            map_data,\n            lat='latitude',\n            lon='longitude',\n            size='observed_cyclists',\n            color='observed_cyclists',\n            hover_name='location_name',\n            hover_data={'route': True, 'observed_cyclists': True},\n            title=\"Cycling Counter Locations\",\n            mapbox_style=\"open-street-map\",\n            zoom=11,\n            height=500\n        )\n        st.plotly_chart(fig_map, use_container_width=True)\n    \n    # Data table\n    st.subheader(\"üìä Detailed Data\")\n    \n    # Display filtered data\n    display_cols = ['location_name', 'direction', 'week_label', 'observed_cyclists', 'route']\n    available_cols = [col for col in display_cols if col in filtered_df.columns]\n    \n    if available_cols:\n        display_df = filtered_df[available_cols].copy()\n        display_df = display_df.sort_values(['week_label', 'location_name'])\n        \n        st.dataframe(\n            display_df,\n            use_container_width=True,\n            hide_index=True\n        )\n    \n    # Summary statistics\n    st.markdown(\"---\")\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        st.subheader(\"üìä Summary Statistics\")\n        \n        # Peak activity location\n        if not filtered_df.empty:\n            peak_location = filtered_df.groupby('location_name')['observed_cyclists'].sum().idxmax()\n            peak_count = filtered_df.groupby('location_name')['observed_cyclists'].sum().max()\n            \n            # Best performing week\n            best_week = filtered_df.groupby('week_label')['observed_cyclists'].sum().idxmax()\n            best_week_count = filtered_df.groupby('week_label')['observed_cyclists'].sum().max()\n            \n            st.write(f\"**Peak Activity Location:** {peak_location} ({peak_count:,} cyclists)\")\n            st.write(f\"**Best Week:** {best_week} ({best_week_count:,} cyclists)\")\n            \n            # Average by direction\n            avg_by_direction = filtered_df.groupby('direction')['observed_cyclists'].mean().round(0)\n            st.write(\"**Average by Direction:**\")\n            for direction, avg in avg_by_direction.items():\n                st.write(f\"  ‚Ä¢ {direction}: {avg:,.0f} cyclists\")\n    \n    with col2:\n        st.subheader(\"‚ÑπÔ∏è Data Information\")\n        \n        # Data info\n        st.write(f\"**Data Range:** {filtered_df['measured_from'].min().strftime('%Y-%m-%d')} to {filtered_df['measured_to'].max().strftime('%Y-%m-%d')}\")\n        st.write(f\"**Total Records:** {len(filtered_df):,}\")\n        st.write(f\"**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        \n        # Data quality info\n        missing_data = filtered_df['observed_cyclists'].isna().sum()\n        if missing_data \u003e 0:\n            st.warning(f\"‚ö†Ô∏è {missing_data} records with missing data\")\n        else:\n            st.success(\"‚úÖ No missing data detected\")\n    \n    # Footer\n    st.markdown(\"---\")\n    st.markdown(\n        \"\"\"\n        \u003cdiv style='text-align: center; color: #666; margin-top: 2rem;'\u003e\n            \u003cp\u003eüö¥ Prague Cycling Dashboard | Data from Keboola | Built with Streamlit\u003c/p\u003e\n            \u003cp\u003e\u003csmall\u003eKeboola Project: DEV - Jan Botorek | Real-time cycling analytics\u003c/small\u003e\u003c/p\u003e\n        \u003c/div\u003e\n        \"\"\",\n        unsafe_allow_html=True\n    )\n\nif __name__ == \"__main__\":\n    main()",
    ],
    id: "25037007",
  },
  authorization: {
    app_proxy: {
      auth_providers: [
        {
          id: "simpleAuth",
          type: "password",
        },
      ],
      auth_rules: [
        {
          type: "pathPrefix",
          value: "/",
          auth_required: true,
          auth: [
            "simpleAuth",
          ],
        },
      ],
    },
  },
}
